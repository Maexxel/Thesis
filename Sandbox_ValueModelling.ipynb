{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disables abls warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import absl.logging\n",
    "absl.logging.set_verbosity('error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/content/drive/MyDrive/Thesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "> ! This will take a very long time if not parallized in multible notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from models.disrnn_utils import create_disrnn_train_state, disrnn_value_trainstep\n",
    "from models.gru_utils import create_gru_train_state, gru_value_trainstep\n",
    "from models.rnn_utils import train_model\n",
    "from torch.utils.data import DataLoader\n",
    "from custom_datasets import custom_collate, from_disk\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 1_000\n",
    "OUT_DIM = 1\n",
    "IN_DIM = 2\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 10\n",
    "NUM_EPOCHS = 5\n",
    "STOP_TRAINING = 3\n",
    "\n",
    "VALUERNN_HIDDEN_SIZES = [50, 20, 10, 5, 4, 3, 2]\n",
    "DISRNN_HIDDEN_SIZES = [10]\n",
    "DISRNN_KL_LOSSES = [0.01, 0.0075, 0.005]\n",
    "\n",
    "OMISSON_PROBABILITIES = [0, 0.1]\n",
    "\n",
    "# Value RNNs\n",
    "for om_prob, hidden_size in product(OMISSON_PROBABILITIES, VALUERNN_HIDDEN_SIZES):\n",
    "    om_prob_str = str(om_prob).replace('.', '')\n",
    "    dataset = from_disk(\"MyStarkweather\", f\"data/belief_{om_prob_str}\")\n",
    "    train_dataloader = DataLoader(dataset,\n",
    "                                  batch_size=10,\n",
    "                                  drop_last=True,\n",
    "                                  collate_fn=custom_collate)\n",
    "\n",
    "    print(\"Training on Hidden Size: \", hidden_size)\n",
    "\n",
    "    master_key = jax.random.PRNGKey(0)\n",
    "    state = create_gru_train_state(master_key,\n",
    "                                learning_rate=LEARNING_RATE,\n",
    "                                hidden_size=hidden_size,\n",
    "                                batch_size=BATCH_SIZE,\n",
    "                                seq_length=SEQ_LENGTH,\n",
    "                                out_dim=OUT_DIM,\n",
    "                                in_dim=IN_DIM)\n",
    "\n",
    "    save_path = f\"data/models/belief_models/vrnn_{str(LEARNING_RATE).replace('.', '')}_{hidden_size}_{om_prob_str}\"\n",
    "    trained_model_state, training_metrics = train_model(state,\n",
    "                                                        train_dataloader,\n",
    "                                                        train_step_fun=gru_value_trainstep,\n",
    "                                                        num_epochs=NUM_EPOCHS,\n",
    "                                                        stop_training=STOP_TRAINING,\n",
    "                                                        print_every_other=1,\n",
    "                                                        save_path=save_path)\n",
    "    del master_key\n",
    "\n",
    "# DisRNNs\n",
    "for om_prob, hidden_size, kl_loss in product(OMISSON_PROBABILITIES, DISRNN_HIDDEN_SIZES, DISRNN_KL_LOSSES):\n",
    "    print(f\"Training om_prob: {om_prob}, hidden_size: {hidden_size}, kl_loss: {kl_loss}\")\n",
    "    om_prob_str = str(om_prob).replace('.', '')\n",
    "    dataset = from_disk(\"MyStarkweather\", f\"data/belief_{om_prob_str}\")\n",
    "    train_dataloader = DataLoader(dataset,\n",
    "                                  batch_size=10,\n",
    "                                  drop_last=True,\n",
    "                                  collate_fn=custom_collate)\n",
    "\n",
    "    master_key = jax.random.PRNGKey(0)\n",
    "    state = create_disrnn_train_state(master_rng_key=master_key,\n",
    "                                      learning_rate=LEARNING_RATE,\n",
    "                                      hidden_size=hidden_size,\n",
    "                                      batch_size=BATCH_SIZE,\n",
    "                                      seq_length=SEQ_LENGTH,\n",
    "                                      in_dim=IN_DIM,\n",
    "                                      out_dim=OUT_DIM,\n",
    "                                      update_mlp_shape=[5, 5, 5],\n",
    "                                      choice_mlp_shape=[2, 2],\n",
    "                                      kl_loss_factor=kl_loss,\n",
    "                                      )\n",
    "\n",
    "    save_path = f\"data/models/belief_models/vrnn_{str(LEARNING_RATE).replace('.', '')}_{hidden_size}_{om_prob_str}_{str(kl_loss).replace('.','')}\"\n",
    "    trained_model_state, training_metrics = train_model(state,\n",
    "                                                        train_dataloader,\n",
    "                                                        train_step_fun=disrnn_value_trainstep,\n",
    "                                                        num_epochs=NUM_EPOCHS,\n",
    "                                                        stop_training=STOP_TRAINING,\n",
    "                                                        print_every_other=1,\n",
    "                                                        save_path=save_path)\n",
    "    del master_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from belief_utils import decode_available_models\n",
    "from belief_analyze import multi_value_analyze, calc_mse, plot_mses\n",
    "model_confs = decode_available_models()\n",
    "trial_dict = multi_value_analyze(0.0, model_confs)\n",
    "mses = calc_mse(trial_dict)\n",
    "plot_mses(mses, model_confs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from belief_analyze import plot_compare_rpes\n",
    "from belief_utils import extract_last_vals, calc_rpe_groups\n",
    "\n",
    "rpegroup_dict = {}\n",
    "for key, value in trial_dict.items():\n",
    "    rpegroup_dict[key] = calc_rpe_groups(value)\n",
    "    \n",
    "plot_compare_rpes(extract_last_vals(rpegroup_dict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
